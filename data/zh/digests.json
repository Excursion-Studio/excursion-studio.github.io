{
  "pageTitle": "文摘 - 远行工作室 测试版",
  "hero": {
    "title": "远行工作室 - 文摘系列",
    "description": "敬请期待远行工作室即将推出的<strong>《论文导读》</strong>和<strong>《论文速递》</strong>系列栏目！"
  },
  "ui": {
    "showMore": "展开更多",
    "showLess": "收起",
    "readMore": "阅读全文",
    "publishedOn": "发布于"
  },
  "sections": [
    {
      "type": "digests",
      "id": "all-digests",
      "items": [
        {
          "category": "paper-guide",
          "categoryName": "论文导读",
          "number": 2,
          "title": "论文导读 2 - 示例论文：如何使用 Paper Guide",
          "description": "这是一篇示例论文。\n展示了 Paper Guide 支持的 Markdown 格式和功能。",
          "date": "2024-01-01",
          "digestPubTime": "2026-02-17",
          "authors": [
            "Paper Guide Team"
          ],
          "tags": [
            "Tutorial",
            "Guide"
          ],
          "venue": "Paper Guide Documentation",
          "pdfUrl": "#",
          "sourcePath": "paper-guide/papers/example-paper/example-paper.md"
        },
        {
          "category": "paper-express",
          "categoryName": "论文速递",
          "number": 1,
          "title": "论文速递 1 - 示例论文：如何使用 Paper Express",
          "description": "这是一篇示例论文。\n展示了 Paper Express 支持的 Markdown 格式和功能。",
          "date": "2024-01-01",
          "digestPubTime": "2026-02-17",
          "authors": [
            "Paper Express Team"
          ],
          "tags": [
            "Tutorial",
            "Express"
          ],
          "venue": "Paper Express Documentation",
          "pdfUrl": "#",
          "sourcePath": "paper-express/papers/example-paper/example-paper.md"
        },
        {
          "category": "paper-guide",
          "categoryName": "论文导读",
          "number": 1,
          "title": "论文导读 1 - Attention Is All You Need",
          "description": "这篇论文提出了具有里程碑意义的 Transformer 架构，彻底改变了 NLP 领域。\n核心创新是自注意力机制（Self-Attention），使模型能够并行处理序列数据。",
          "date": "2017-06-12",
          "digestPubTime": "2026-02-14",
          "authors": [
            "Ashish Vaswani",
            "Noam Shazeer",
            "Niki Parmar",
            "Jakob Uszkoreit",
            "Llion Jones",
            "Aidan N. Gomez",
            "Łukasz Kaiser",
            "Illia Polosukhin"
          ],
          "tags": [
            "Transformer",
            "NLP",
            "Deep Learning",
            "Attention Mechanism"
          ],
          "venue": "NeurIPS 2017",
          "pdfUrl": "https://arxiv.org/abs/1706.03762",
          "sourcePath": "paper-guide/papers/attention-is-all-you-need/attention-is-all-you-need.md"
        }
      ]
    }
  ]
}